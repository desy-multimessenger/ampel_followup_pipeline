{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from ampel.ztf.archive.ArchiveDB import ArchiveDB\n",
    "from astropy.time import Time\n",
    "import itertools\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize\n",
    "import scipy as scp\n",
    "import datetime\n",
    "import ztfquery\n",
    "import datetime\n",
    "import re\n",
    "from ztfquery import alert\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from matplotlib.patches import Circle\n",
    "from matplotlib.collections import PatchCollection\n",
    "import csv\n",
    "import os,io\n",
    "import pickle\n",
    "# import pymongo\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy import units as u\n",
    "import getpass\n",
    "import psycopg2 \n",
    "import sqlalchemy\n",
    "import healpy as hp\n",
    "from astropy.io import fits\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "from ligo.gracedb.rest import GraceDb\n",
    "import lxml.etree\n",
    "from pathlib import Path\n",
    "import os\n",
    "# import gzip\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_ligo_dir = os.path.join(Path().absolute(), \"LIGO_skymaps\")\n",
    "candidate_output_dir = os.path.join(Path().absolute(), \"LIGO_candidates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Setup LIGO client\n",
    "\n",
    "ligo_client = GraceDb()\n",
    "\n",
    "try:\n",
    "    r = ligo_client.ping()\n",
    "except HTTPError as e:\n",
    "    raise(e.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(\".AMPEL_user.txt\", \"r\") as f:\n",
    "        username = f.read()\n",
    "except FileNotFoundError:\n",
    "    username = getpass.getpass(prompt='Username: ', stream=None)\n",
    "    with open(\".AMPEL_user.txt\", \"wb\") as f:\n",
    "        f.write(username.encode())\n",
    "        \n",
    "try:\n",
    "    with open(\".AMPEL_pass.txt\", \"r\") as f:\n",
    "        password = f.read()\n",
    "except FileNotFoundError:\n",
    "    password = getpass.getpass(prompt='Password: ', stream=None)\n",
    "    with open(\".AMPEL_pass.txt\", \"wb\") as f:\n",
    "        f.write(password.encode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    client = ArchiveDB('postgresql://{0}:{1}@localhost:5432/ztfarchive'.format(username, password))\n",
    "except sqlalchemy.exc.OperationalError as e:\n",
    "    print(\"You can't access the archive database without first opening the port.\")\n",
    "    print(\"Open a new terminal, and into that terminal, run the following command:\")\n",
    "    print(\"ssh -L5432:localhost:5433 ztf-wgs.zeuthen.desy.de\")\n",
    "    print(\"If that command doesn't work, you are either not a desy user or you have a problem in your ssh config.\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def reassemble_alert(candid):\n",
    "#     mock_alert = client.get_alert(candid)\n",
    "#     cutouts = client.get_cutout(candid)\n",
    "#     for k in cutouts:\n",
    "#         mock_alert['cutout{}'.format(k.title())] = {'stampData': cutouts[k], 'fileName': 'dunno'}\n",
    "#     mock_alert['schemavsn'] = 'dunno'\n",
    "#     mock_alert['publisher'] = 'dunno'\n",
    "#     for pp in [mock_alert['candidate']] + mock_alert['prv_candidates']:\n",
    "#         #if pp['isdiffpos'] is not None:\n",
    "#             #pp['isdiffpos'] = ['f', 't'][pp['isdiffpos']]\n",
    "#         pp['pdiffimfilename'] = 'dunno'\n",
    "#         pp['programpi'] = 'dunno'\n",
    "#         pp['ssnamenr'] = 'dunno'\n",
    "        \n",
    "#     return mock_alert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GravWaveScanner:\n",
    "    \n",
    "    def __init__(self, gw_name=None, prob_threshold=0.9, cone_nside=64, t_max=None):\n",
    "        self.gw_path, self.output_path = self.get_superevent(gw_name)\n",
    "        self.cone_nside = cone_nside\n",
    "        self.parsed_file = self.read_map()\n",
    "        self.merger_time = Time(self.parsed_file[1].header[\"DATE-OBS\"], format=\"isot\", scale=\"utc\")\n",
    "        \n",
    "        if t_max is not None:\n",
    "            self.t_max = t_max\n",
    "        else:\n",
    "            self.t_max = Time(self.merger_time.jd + 3,format='jd')\n",
    "        \n",
    "        print(\"MERGER TIME: {0}\".format(self.merger_time))\n",
    "        \n",
    "        self.data = self.parsed_file[1].data\n",
    "        self.prob_map = hp.read_map(self.gw_path)\n",
    "        self.prob_threshold = prob_threshold\n",
    "        self.pixel_threshold = self.find_pixel_threshold(self.data[\"PROB\"])\n",
    "        self.scanned_pixels = []\n",
    "        self.map_coords = self.unpack_skymap()\n",
    "        self.cone_ids, self.cone_coords = self.find_cone_coords()\n",
    "        self.cache = []\n",
    "        \n",
    "    def get_superevent(self, name):\n",
    "        if name is None:\n",
    "            superevent_iterator = ligo_client.superevents('category: Production')\n",
    "            superevent_ids = [superevent['superevent_id'] for superevent in superevent_iterator]\n",
    "            name = superevent_ids[0]\n",
    "\n",
    "        latest_gw = ligo_client.superevent(name)\n",
    "        latest_voevent = ligo_client.voevents(name).json()[\"voevents\"][-1]    \n",
    "        print(\"Found voevent {0}\".format(latest_voevent[\"filename\"]))\n",
    "\n",
    "        url = 'https://gracedb.ligo.org/api/superevents/S190728q/files/S190728q-5-Update.xml,0'\n",
    "        response = requests.get(url)\n",
    "\n",
    "        root = lxml.etree.fromstring(response.content)\n",
    "        params = {elem.attrib['name']:\n",
    "                  elem.attrib['value']\n",
    "                  for elem in root.iterfind('.//Param')}\n",
    "        \n",
    "        \n",
    "\n",
    "        latest_skymap = params[\"skymap_fits\"]\n",
    "\n",
    "        print(\"Latest skymap URL: {0}\".format(latest_skymap))\n",
    "\n",
    "        base_file_name = os.path.basename(latest_skymap)\n",
    "        savepath = os.path.join(base_ligo_dir, base_file_name)\n",
    "\n",
    "        print(\"Saving to: {0}\".format(savepath))\n",
    "        response = requests.get(latest_skymap)\n",
    "\n",
    "        with open(savepath, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "            \n",
    "        output_file = \"{0}/{1}_{2}.pdf\".format(candidate_output_dir, name, latest_voevent[\"N\"])\n",
    "\n",
    "        return savepath, output_file\n",
    "\n",
    "    def add_scan(self, ra, dec):\n",
    "        self.scanned_points += [(ra, dec)]\n",
    "        \n",
    "    def read_map(self, ):\n",
    "        print(\"Reading file: {0}\".format(self.gw_path))\n",
    "        f = fits.open(self.gw_path)\n",
    "        return f\n",
    "        \n",
    "        \n",
    "    def find_pixel_threshold(self, data):\n",
    "        print(\"\")\n",
    "        ranked_pixels = np.sort(data)[::-1]\n",
    "        int_sum = 0.0\n",
    "        pixel_threshold = 0.0\n",
    "\n",
    "        for i, prob in enumerate(ranked_pixels):\n",
    "            int_sum += prob\n",
    "            if int_sum > self.prob_threshold:\n",
    "                print(\"Threshold found! \\n To reach {0}% of probability, pixels with \"\n",
    "                      \"probability greater than {1} are included\".format(\n",
    "                          int_sum*100., prob))\n",
    "                pixel_threshold = prob\n",
    "                break\n",
    "                \n",
    "        return pixel_threshold\n",
    "    \n",
    "    def find_cone_ids(self):\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def extract_ra_dec(nside, index):\n",
    "        (colat, ra) = hp.pix2ang(nside, index, nest=True)\n",
    "        dec = np.pi/2. - colat\n",
    "        return (ra, dec)\n",
    "    \n",
    "    @staticmethod\n",
    "    def extract_npix(nside, ra, dec):\n",
    "        colat = np.pi/2. - dec\n",
    "        return hp.ang2pix(nside, colat, ra, nest=True)\n",
    "    \n",
    "    def unpack_skymap(self):\n",
    "\n",
    "        ligo_nside = hp.npix2nside(len(self.data[\"PROB\"]))\n",
    "\n",
    "        threshold = self.find_pixel_threshold(self.data[\"PROB\"])\n",
    "\n",
    "        mask = self.data[\"PROB\"] > threshold\n",
    "        \n",
    "        map_coords = []\n",
    "\n",
    "        print(\"Checking which pixels are within the contour:\")\n",
    "\n",
    "        for i in tqdm(range(hp.nside2npix(ligo_nside))):\n",
    "            if mask[i]:\n",
    "                map_coords.append(self.extract_ra_dec(ligo_nside, i))\n",
    "                \n",
    "        print(\"Total pixel area: {0} degrees\".format(\n",
    "            hp.nside2pixarea(ligo_nside, degrees=True)*float(len(map_coords))))\n",
    "\n",
    "        map_coords = np.array(map_coords, dtype=np.dtype([(\"ra\", np.float), \n",
    "                                                          (\"dec\", np.float)]))\n",
    "        \n",
    "        return map_coords\n",
    "\n",
    "    def find_cone_coords(self):\n",
    "        cone_ids = []\n",
    "\n",
    "        for ra, dec in self.map_coords:\n",
    "\n",
    "            cone_ids.append(self.extract_npix(self.cone_nside, ra, dec))\n",
    "\n",
    "        cone_ids = list(set(cone_ids))        \n",
    "        \n",
    "        cone_coords = []\n",
    "        \n",
    "        for i in tqdm(cone_ids):\n",
    "            cone_coords.append(self.extract_ra_dec(self.cone_nside, i))\n",
    "\n",
    "        cone_coords = np.array(\n",
    "            cone_coords, dtype=np.dtype([(\"ra\", np.float), (\"dec\", np.float)])\n",
    "        )\n",
    "        \n",
    "        return cone_ids, cone_coords\n",
    "    \n",
    "    @staticmethod\n",
    "    def wrap_around_180(ra):\n",
    "        ra[ra > np.pi] -= 2*np.pi\n",
    "        return ra\n",
    "        \n",
    "        \n",
    "        \n",
    "    def plot_skymap(self):\n",
    "        \n",
    "        plt.subplot(projection=\"aitoff\")\n",
    "\n",
    "        sc = plt.scatter(wrap_around_180(self.map_coords[\"ra\"]), self.map_coords[\"dec\"],\n",
    "                        c=new_probs[mask], vmin=0.,  vmax=max(new_probs), s=1e-4)\n",
    "        plt.title(\"LIGO SKYMAP\")\n",
    "        plt.show()\n",
    "        \n",
    "        plt.subplot(projection=\"aitoff\")\n",
    "\n",
    "        sc = plt.scatter(wrap_around_180(self.cone_coords[\"ra\"]), self.cone_coords[\"dec\"])\n",
    "        plt.title(\"CONE REGION\")\n",
    "        plt.show()\n",
    "        \n",
    "    def scan_cones(self, t_max=Time.now()):\n",
    "        \n",
    "        scan_radius = np.degrees(hp.max_pixrad(self.cone_nside))\n",
    "        print(\"Commencing Ampel queries!\")\n",
    "        print(\"Scan radius is\", scan_radius)\n",
    "        print(\"So far, {0} pixels out of {1} have already been scanned.\".format(\n",
    "            len(self.scanned_pixels), len(self.cone_ids)\n",
    "        ))\n",
    "        \n",
    "        for i, cone_id in enumerate(tqdm(list(self.cone_ids)[:5])):\n",
    "            ra, dec = self.cone_coords[i]\n",
    "            \n",
    "            if cone_id not in self.scanned_pixels:\n",
    "                self.cache += self.query_ampel(ra, dec, scan_radius, t_max)\n",
    "                self.scanned_pixels.append(cone_id)\n",
    "        \n",
    "        print(\"Scanned {0} pixels\".format(len(self.scanned_pixels)))\n",
    "        print(\"Found {0} candidates\".format(len(self.cache)))\n",
    "        \n",
    "        self.create_candidate_summary()\n",
    "        \n",
    "    \n",
    "    def filter_f_no_prv(self, res):\n",
    "        # Positive detection\n",
    "        if res['candidate']['isdiffpos'] in [\"t\", \"1\"]:\n",
    "                        \n",
    "            # Remove stars et al.\n",
    "#             if res[\"sgscore1\"] > 0.8:\n",
    "#                 return False\n",
    "\n",
    "            if res['candidate'][\"rb\"] < 0.2:\n",
    "                return False\n",
    "\n",
    "            return True\n",
    "                    \n",
    "        return False\n",
    "    \n",
    "    def filter_f_history(self, res):\n",
    "        # Veto past detections, but not past upper limits\n",
    "\n",
    "        for prv_detection in res[\"prv_candidates\"]:\n",
    "            if np.logical_and(prv_detection[\"isdiffpos\"] is not None, prv_detection[\"jd\"] < self.merger_time.jd):\n",
    "                return False\n",
    "\n",
    "        # Require 2 detections\n",
    "\n",
    "        n_detections = len([x for x in res[\"prv_candidates\"] if np.logical_and(\n",
    "            x[\"isdiffpos\"] is not None, x[\"jd\"] > self.merger_time.jd)])\n",
    "\n",
    "        if n_detections < 1:\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "            \n",
    "    def query_ampel(self, ra, dec, rad, t_max):\n",
    "        ztf_object = client.ztf_object = client.get_alerts_in_cone(\n",
    "            ra, dec, rad, self.merger_time.jd, self.t_max.jd, with_history=False)\n",
    "        query_res = [i for i in ztf_object]\n",
    "\n",
    "        diff = [\"t\", \"1\"]\n",
    "        candids = []\n",
    "        for res in query_res:\n",
    "            if self.filter_f_no_prv(res):                        \n",
    "                candids.append(res[\"candid\"])\n",
    "        \n",
    "        ztf_object = client.get_alerts(candids, with_history=True)\n",
    "        query_res = [i for i in ztf_object]\n",
    "        final_res = []\n",
    "        \n",
    "        for res in query_res:\n",
    "            if self.filter_f_history(res):                        \n",
    "                final_res.append(res)\n",
    "                \n",
    "        return final_res\n",
    "    \n",
    "    @staticmethod\n",
    "    def reassemble_alert(mock_alert):\n",
    "        cutouts = client.get_cutout(mock_alert[\"candid\"])\n",
    "        for k in cutouts:\n",
    "            mock_alert['cutout{}'.format(k.title())] = {'stampData': cutouts[k], 'fileName': 'dunno'}\n",
    "        mock_alert['schemavsn'] = 'dunno'\n",
    "        mock_alert['publisher'] = 'dunno'\n",
    "        for pp in [mock_alert['candidate']] + mock_alert['prv_candidates']:\n",
    "            #if pp['isdiffpos'] is not None:\n",
    "                #pp['isdiffpos'] = ['f', 't'][pp['isdiffpos']]\n",
    "            pp['pdiffimfilename'] = 'dunno'\n",
    "            pp['programpi'] = 'dunno'\n",
    "            pp['ssnamenr'] = 'dunno'\n",
    "\n",
    "        return mock_alert\n",
    "    \n",
    "    def create_candidate_summary(self):\n",
    "        \n",
    "        print(\"Saving to:\", self.output_path)\n",
    "    \n",
    "        with PdfPages(self.output_path) as pdf:\n",
    "            for old_alert in tqdm(self.cache):\n",
    "                mock_alert = self.reassemble_alert(old_alert)\n",
    "                fig = alert.display_alert(mock_alert)\n",
    "                fig.text(0,0,mock_alert[\"objectId\"])\n",
    "                pdf.savefig()\n",
    "                plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found voevent S190728q-5-Update.xml\n",
      "Latest skymap URL: https://gracedb.ligo.org/api/superevents/S190728q/files/LALInference.offline.fits.gz\n",
      "Saving to: /Users/avocado/ZTF_Neutrino_ToO/LIGO_skymaps/LALInference.offline.fits.gz\n",
      "Reading file: /Users/avocado/ZTF_Neutrino_ToO/LIGO_skymaps/LALInference.offline.fits.gz\n",
      "MERGER TIME: 2019-07-28T06:45:10.548\n",
      "NSIDE = 1024\n",
      "ORDERING = NESTED in fits file\n",
      "INDXSCHM = IMPLICIT\n",
      "Ordering converted to RING\n",
      "\n",
      "Threshold found! \n",
      " To reach 90.00009741504594% of probability, pixels with probability greater than 3.8098001157350675e-06 are included\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/12582912 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold found! \n",
      " To reach 90.00009741504594% of probability, pixels with probability greater than 3.8098001157350675e-06 are included\n",
      "Checking which pixels are within the contour:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12582912/12582912 [00:09<00:00, 1337887.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pixel area: 103.96750030053329 degrees\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153/153 [00:00<00:00, 15792.51it/s]\n"
     ]
    }
   ],
   "source": [
    "gw = GravWaveScanner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commencing Ampel queries!\n",
      "Scan radius is 0.9541480607387777\n",
      "So far, 0 pixels out of 153 have already been scanned.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:09<00:00,  1.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanned 5 pixels\n",
      "Found 12 candidates\n",
      "Saving to: /Users/avocado/ZTF_Neutrino_ToO/LIGO_candidates/S190728q_5.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]/Users/avocado/anaconda2/envs/ztf_too_env/lib/python3.7/site-packages/pandas/plotting/_converter.py:129: FutureWarning: Using an implicitly registered datetime converter for a matplotlib plotting method. The converter was registered by pandas on import. Future versions of pandas will require you to explicitly register matplotlib converters.\n",
      "\n",
      "To register the converters:\n",
      "\t>>> from pandas.plotting import register_matplotlib_converters\n",
      "\t>>> register_matplotlib_converters()\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "100%|██████████| 12/12 [00:06<00:00,  2.20it/s]\n"
     ]
    }
   ],
   "source": [
    "gw.scan_cones()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(gw.parsed_file[1].header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ztf_too_env",
   "language": "python",
   "name": "ztf_too_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
